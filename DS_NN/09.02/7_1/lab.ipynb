{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 6d958be074577803d12ecdefd02955f39262c83c16fe9348329d7fe0b5c001ce so we will re-download the data.\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"# Создаем последовательную модель\\nmodel = Sequential()\\n# Формирование вектора, отвечающего за размерность входных данных: \\n# либо (кол-во каналов, ширина, высота), либо (ширина, высота, кол-во каналов) \\n# (в зависимости от значения параметра \"image_data_format\" в файле keras.json)\\nshape_vector = X_train.shape[1:]\\n# Первый сверточный слой\\nmodel.add(Conv2D(32, (3, 3), padding=\\'same\\',\\n                        input_shape=shape_vector, activation=\\'relu\\'))\\n# Второй сверточный слой\\nmodel.add(Conv2D(32, (3, 3), activation=\\'relu\\', padding=\\'same\\'))\\n# Первый слой подвыборки\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\n# Слой регуляризации Dropout\\nmodel.add(Dropout(0.25))\\n\\n# Третий сверточный слой\\nmodel.add(Conv2D(64, (3, 3), padding=\\'same\\', activation=\\'relu\\'))\\n# Четвертый сверточный слой\\nmodel.add(Conv2D(64, (3, 3), activation=\\'relu\\'))\\n# Второй слой подвыборки\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\n# Слой регуляризации Dropout\\nmodel.add(Dropout(0.25))\\n# Слой преобразования данных из 2D представления в плоское\\nmodel.add(Flatten())\\n# Полносвязный слой для классификации\\nmodel.add(Dense(512, activation=\\'relu\\'))\\n# Слой регуляризации Dropout\\nmodel.add(Dropout(0.5))\\n# Выходной полносвязный слой\\nmodel.add(Dense(nb_classes, activation=\\'softmax\\'))\\n\\n# Задаем параметры оптимизации\\nsgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\\nmodel.compile(loss=\\'categorical_crossentropy\\',\\n              optimizer=sgd,\\n              metrics=[\\'accuracy\\'])\\n# Обучаем модель\\nmodel.fit(X_train, Y_train,\\n              batch_size=batch_size,\\n              epochs=nb_epoch,\\n              validation_split=0.1,\\n              shuffle=True,\\n              verbose=1)\\n\\n# Оцениваем качество обучения модели на тестовых данных\\nscores = model.evaluate(X_test, Y_test, verbose=0)\\nprint(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Задаем seed для повторяемости результатов\n",
    "numpy.random.seed(42)\n",
    "\n",
    "# Загружаем данные\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# Размер мини-выборки\n",
    "batch_size = 32\n",
    "# Количество классов изображений\n",
    "nb_classes = 10\n",
    "# Количество эпох для обучения\n",
    "nb_epoch = 1\n",
    "\n",
    "# Нормализуем данные\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Преобразуем метки в категории\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Количество эпох"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 20ms/step - accuracy: 0.2593 - loss: 1.9974 - val_accuracy: 0.5028 - val_loss: 1.3983\n",
      "Epoch 2/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 24ms/step - accuracy: 0.4959 - loss: 1.3800 - val_accuracy: 0.5960 - val_loss: 1.0960\n",
      "Epoch 3/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 24ms/step - accuracy: 0.5815 - loss: 1.1744 - val_accuracy: 0.6598 - val_loss: 0.9785\n",
      "Epoch 4/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 27ms/step - accuracy: 0.6255 - loss: 1.0531 - val_accuracy: 0.6912 - val_loss: 0.8828\n",
      "Epoch 5/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 30ms/step - accuracy: 0.6595 - loss: 0.9642 - val_accuracy: 0.7110 - val_loss: 0.8420\n",
      "Epoch 6/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 30ms/step - accuracy: 0.6811 - loss: 0.9048 - val_accuracy: 0.7192 - val_loss: 0.7946\n",
      "Epoch 7/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 31ms/step - accuracy: 0.7022 - loss: 0.8367 - val_accuracy: 0.7266 - val_loss: 0.7823\n",
      "Epoch 8/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 30ms/step - accuracy: 0.7182 - loss: 0.7901 - val_accuracy: 0.7304 - val_loss: 0.8017\n",
      "Epoch 9/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 31ms/step - accuracy: 0.7334 - loss: 0.7478 - val_accuracy: 0.7096 - val_loss: 0.8318\n",
      "Epoch 10/10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 27ms/step - accuracy: 0.7435 - loss: 0.7207 - val_accuracy: 0.7414 - val_loss: 0.7620\n",
      "Точность работы на тестовых данных: 72.92%\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Задаем seed для повторяемости результатов\n",
    "numpy.random.seed(42)\n",
    "\n",
    "# Загружаем данные\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# Размер мини-выборки\n",
    "batch_size = 32\n",
    "# Количество классов изображений\n",
    "nb_classes = 10\n",
    "# Количество эпох для обучения\n",
    "nb_epoch = 10\n",
    "\n",
    "# Нормализуем данные\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Преобразуем метки в категории\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "# Формирование вектора, отвечающего за размерность входных данных: \n",
    "# либо (кол-во каналов, ширина, высота), либо (ширина, высота, кол-во каналов) \n",
    "# (в зависимости от значения параметра \"image_data_format\" в файле keras.json)\n",
    "shape_vector = X_train.shape[1:]\n",
    "# Первый сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=shape_vector, activation='relu'))\n",
    "# Второй сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# Первый слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Третий сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# Четвертый сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "# Слой преобразования данных из 2D представления в плоское\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой для классификации\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.5))\n",
    "# Выходной полносвязный слой\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# Задаем параметры оптимизации\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# Обучаем модель\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "\n",
    "# Оцениваем качество обучения модели на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 20ms/step - accuracy: 0.2704 - loss: 1.9585 - val_accuracy: 0.4852 - val_loss: 1.4836\n",
      "Epoch 2/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 21ms/step - accuracy: 0.5317 - loss: 1.3036 - val_accuracy: 0.6298 - val_loss: 1.0407\n",
      "Epoch 3/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 23ms/step - accuracy: 0.5950 - loss: 1.1320 - val_accuracy: 0.6544 - val_loss: 0.9688\n",
      "Epoch 4/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 25ms/step - accuracy: 0.6377 - loss: 1.0223 - val_accuracy: 0.6828 - val_loss: 0.9113\n",
      "Epoch 5/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 26ms/step - accuracy: 0.6753 - loss: 0.9205 - val_accuracy: 0.7176 - val_loss: 0.8425\n",
      "Epoch 6/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 30ms/step - accuracy: 0.6945 - loss: 0.8609 - val_accuracy: 0.7314 - val_loss: 0.7941\n",
      "Epoch 7/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 29ms/step - accuracy: 0.7160 - loss: 0.8040 - val_accuracy: 0.7446 - val_loss: 0.7389\n",
      "Epoch 8/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 29ms/step - accuracy: 0.7297 - loss: 0.7597 - val_accuracy: 0.7604 - val_loss: 0.7206\n",
      "Epoch 9/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 29ms/step - accuracy: 0.7405 - loss: 0.7325 - val_accuracy: 0.7374 - val_loss: 0.7682\n",
      "Epoch 10/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 28ms/step - accuracy: 0.7572 - loss: 0.6902 - val_accuracy: 0.7726 - val_loss: 0.6715\n",
      "Epoch 11/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 30ms/step - accuracy: 0.7647 - loss: 0.6684 - val_accuracy: 0.7642 - val_loss: 0.7306\n",
      "Epoch 12/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 28ms/step - accuracy: 0.7711 - loss: 0.6617 - val_accuracy: 0.7524 - val_loss: 0.7601\n",
      "Epoch 13/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 29ms/step - accuracy: 0.7782 - loss: 0.6379 - val_accuracy: 0.7722 - val_loss: 0.6807\n",
      "Epoch 14/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 29ms/step - accuracy: 0.7826 - loss: 0.6188 - val_accuracy: 0.7690 - val_loss: 0.6967\n",
      "Epoch 15/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 29ms/step - accuracy: 0.7877 - loss: 0.6091 - val_accuracy: 0.7626 - val_loss: 0.7189\n",
      "Epoch 16/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 29ms/step - accuracy: 0.7951 - loss: 0.5883 - val_accuracy: 0.7792 - val_loss: 0.6539\n",
      "Epoch 17/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 29ms/step - accuracy: 0.7968 - loss: 0.5843 - val_accuracy: 0.7766 - val_loss: 0.6693\n",
      "Epoch 18/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 30ms/step - accuracy: 0.7972 - loss: 0.5770 - val_accuracy: 0.7742 - val_loss: 0.6894\n",
      "Epoch 19/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 29ms/step - accuracy: 0.8023 - loss: 0.5624 - val_accuracy: 0.7780 - val_loss: 0.6788\n",
      "Epoch 20/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 20ms/step - accuracy: 0.7999 - loss: 0.5729 - val_accuracy: 0.7810 - val_loss: 0.6584\n",
      "Точность работы на тестовых данных: 77.50%\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Задаем seed для повторяемости результатов\n",
    "numpy.random.seed(42)\n",
    "\n",
    "# Загружаем данные\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# Размер мини-выборки\n",
    "batch_size = 32\n",
    "# Количество классов изображений\n",
    "nb_classes = 10\n",
    "# Количество эпох для обучения\n",
    "nb_epoch = 20\n",
    "\n",
    "# Нормализуем данные\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Преобразуем метки в категории\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "# Формирование вектора, отвечающего за размерность входных данных: \n",
    "# либо (кол-во каналов, ширина, высота), либо (ширина, высота, кол-во каналов) \n",
    "# (в зависимости от значения параметра \"image_data_format\" в файле keras.json)\n",
    "shape_vector = X_train.shape[1:]\n",
    "# Первый сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=shape_vector, activation='relu'))\n",
    "# Второй сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# Первый слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Третий сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# Четвертый сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "# Слой преобразования данных из 2D представления в плоское\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой для классификации\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.5))\n",
    "# Выходной полносвязный слой\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# Задаем параметры оптимизации\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# Обучаем модель\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "\n",
    "# Оцениваем качество обучения модели на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Размер мини-пакетов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.2612 - loss: 1.9805 - val_accuracy: 0.4610 - val_loss: 1.4764\n",
      "Точность работы на тестовых данных: 46.14%\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Задаем seed для повторяемости результатов\n",
    "numpy.random.seed(42)\n",
    "\n",
    "# Загружаем данные\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# Размер мини-выборки\n",
    "batch_size = 16\n",
    "# Количество классов изображений\n",
    "nb_classes = 10\n",
    "# Количество эпох для обучения\n",
    "nb_epoch = 1\n",
    "\n",
    "# Нормализуем данные\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Преобразуем метки в категории\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "# Формирование вектора, отвечающего за размерность входных данных: \n",
    "# либо (кол-во каналов, ширина, высота), либо (ширина, высота, кол-во каналов) \n",
    "# (в зависимости от значения параметра \"image_data_format\" в файле keras.json)\n",
    "shape_vector = X_train.shape[1:]\n",
    "# Первый сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=shape_vector, activation='relu'))\n",
    "# Второй сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# Первый слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Третий сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# Четвертый сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "# Слой преобразования данных из 2D представления в плоское\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой для классификации\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.5))\n",
    "# Выходной полносвязный слой\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# Задаем параметры оптимизации\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# Обучаем модель\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "\n",
    "# Оцениваем качество обучения модели на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 10ms/step - accuracy: 0.2088 - loss: 2.1150 - val_accuracy: 0.3640 - val_loss: 1.6978\n",
      "Точность работы на тестовых данных: 37.54%\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Задаем seed для повторяемости результатов\n",
    "numpy.random.seed(42)\n",
    "\n",
    "# Загружаем данные\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# Размер мини-выборки\n",
    "batch_size = 8\n",
    "# Количество классов изображений\n",
    "nb_classes = 10\n",
    "# Количество эпох для обучения\n",
    "nb_epoch = 1\n",
    "\n",
    "# Нормализуем данные\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Преобразуем метки в категории\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "# Формирование вектора, отвечающего за размерность входных данных: \n",
    "# либо (кол-во каналов, ширина, высота), либо (ширина, высота, кол-во каналов) \n",
    "# (в зависимости от значения параметра \"image_data_format\" в файле keras.json)\n",
    "shape_vector = X_train.shape[1:]\n",
    "# Первый сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=shape_vector, activation='relu'))\n",
    "# Второй сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# Первый слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Третий сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# Четвертый сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "# Слой преобразования данных из 2D представления в плоское\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой для классификации\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.5))\n",
    "# Выходной полносвязный слой\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# Задаем параметры оптимизации\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# Обучаем модель\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "\n",
    "# Оцениваем качество обучения модели на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 56ms/step - accuracy: 0.2283 - loss: 2.0714 - val_accuracy: 0.4612 - val_loss: 1.4771\n",
      "Точность работы на тестовых данных: 45.20%\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Задаем seed для повторяемости результатов\n",
    "numpy.random.seed(42)\n",
    "\n",
    "# Загружаем данные\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# Размер мини-выборки\n",
    "batch_size = 64\n",
    "# Количество классов изображений\n",
    "nb_classes = 10\n",
    "# Количество эпох для обучения\n",
    "nb_epoch = 1\n",
    "\n",
    "# Нормализуем данные\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Преобразуем метки в категории\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "# Формирование вектора, отвечающего за размерность входных данных: \n",
    "# либо (кол-во каналов, ширина, высота), либо (ширина, высота, кол-во каналов) \n",
    "# (в зависимости от значения параметра \"image_data_format\" в файле keras.json)\n",
    "shape_vector = X_train.shape[1:]\n",
    "# Первый сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=shape_vector, activation='relu'))\n",
    "# Второй сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# Первый слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Третий сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# Четвертый сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "# Слой преобразования данных из 2D представления в плоское\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой для классификации\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.5))\n",
    "# Выходной полносвязный слой\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# Задаем параметры оптимизации\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# Обучаем модель\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "\n",
    "# Оцениваем качество обучения модели на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Коэффициенты регуляризации "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все коэффициенты заданы по 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.2266 - loss: 2.0552 - val_accuracy: 0.4570 - val_loss: 1.5060\n",
      "Точность работы на тестовых данных: 46.17%\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Задаем seed для повторяемости результатов\n",
    "numpy.random.seed(42)\n",
    "\n",
    "# Загружаем данные\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# Размер мини-выборки\n",
    "batch_size = 32\n",
    "# Количество классов изображений\n",
    "nb_classes = 10\n",
    "# Количество эпох для обучения\n",
    "nb_epoch = 1\n",
    "\n",
    "# Нормализуем данные\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Преобразуем метки в категории\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "# Формирование вектора, отвечающего за размерность входных данных: \n",
    "# либо (кол-во каналов, ширина, высота), либо (ширина, высота, кол-во каналов) \n",
    "# (в зависимости от значения параметра \"image_data_format\" в файле keras.json)\n",
    "shape_vector = X_train.shape[1:]\n",
    "# Первый сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=shape_vector, activation='relu'))\n",
    "# Второй сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# Первый слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Третий сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# Четвертый сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.5))\n",
    "# Слой преобразования данных из 2D представления в плоское\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой для классификации\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.5))\n",
    "# Выходной полносвязный слой\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# Задаем параметры оптимизации\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# Обучаем модель\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "\n",
    "# Оцениваем качество обучения модели на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые коэффициенты заданы по 0.3, а последний 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 25ms/step - accuracy: 0.2724 - loss: 1.9646 - val_accuracy: 0.5052 - val_loss: 1.3697\n",
      "Точность работы на тестовых данных: 50.41%\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Задаем seed для повторяемости результатов\n",
    "numpy.random.seed(42)\n",
    "\n",
    "# Загружаем данные\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# Размер мини-выборки\n",
    "batch_size = 32\n",
    "# Количество классов изображений\n",
    "nb_classes = 10\n",
    "# Количество эпох для обучения\n",
    "nb_epoch = 1\n",
    "\n",
    "# Нормализуем данные\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Преобразуем метки в категории\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "# Формирование вектора, отвечающего за размерность входных данных: \n",
    "# либо (кол-во каналов, ширина, высота), либо (ширина, высота, кол-во каналов) \n",
    "# (в зависимости от значения параметра \"image_data_format\" в файле keras.json)\n",
    "shape_vector = X_train.shape[1:]\n",
    "# Первый сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=shape_vector, activation='relu'))\n",
    "# Второй сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# Первый слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Третий сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# Четвертый сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.3))\n",
    "# Слой преобразования данных из 2D представления в плоское\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой для классификации\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Выходной полносвязный слой\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# Задаем параметры оптимизации\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# Обучаем модель\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "\n",
    "# Оцениваем качество обучения модели на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скорость обучения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 27ms/step - accuracy: 0.0971 - loss: 2.3120 - val_accuracy: 0.1058 - val_loss: 2.3075\n",
      "Точность работы на тестовых данных: 10.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Задаем seed для повторяемости результатов\n",
    "numpy.random.seed(42)\n",
    "\n",
    "# Загружаем данные\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# Размер мини-выборки\n",
    "batch_size = 32\n",
    "# Количество классов изображений\n",
    "nb_classes = 10\n",
    "# Количество эпох для обучения\n",
    "nb_epoch = 1\n",
    "\n",
    "# Нормализуем данные\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Преобразуем метки в категории\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "# Формирование вектора, отвечающего за размерность входных данных: \n",
    "# либо (кол-во каналов, ширина, высота), либо (ширина, высота, кол-во каналов) \n",
    "# (в зависимости от значения параметра \"image_data_format\" в файле keras.json)\n",
    "shape_vector = X_train.shape[1:]\n",
    "# Первый сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=shape_vector, activation='relu'))\n",
    "# Второй сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# Первый слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Третий сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# Четвертый сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "# Слой преобразования данных из 2D представления в плоское\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой для классификации\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.5))\n",
    "# Выходной полносвязный слой\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# Задаем параметры оптимизации\n",
    "sgd = SGD(learning_rate=0.1, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# Обучаем модель\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "\n",
    "# Оцениваем качество обучения модели на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 23ms/step - accuracy: 0.1482 - loss: 2.2216 - val_accuracy: 0.3414 - val_loss: 1.7581\n",
      "Точность работы на тестовых данных: 34.27%\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Задаем seed для повторяемости результатов\n",
    "numpy.random.seed(42)\n",
    "\n",
    "# Загружаем данные\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# Размер мини-выборки\n",
    "batch_size = 32\n",
    "# Количество классов изображений\n",
    "nb_classes = 10\n",
    "# Количество эпох для обучения\n",
    "nb_epoch = 1\n",
    "\n",
    "# Нормализуем данные\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Преобразуем метки в категории\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "# Формирование вектора, отвечающего за размерность входных данных: \n",
    "# либо (кол-во каналов, ширина, высота), либо (ширина, высота, кол-во каналов) \n",
    "# (в зависимости от значения параметра \"image_data_format\" в файле keras.json)\n",
    "shape_vector = X_train.shape[1:]\n",
    "# Первый сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=shape_vector, activation='relu'))\n",
    "# Второй сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# Первый слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Третий сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# Четвертый сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "# Слой преобразования данных из 2D представления в плоское\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой для классификации\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.5))\n",
    "# Выходной полносвязный слой\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# Задаем параметры оптимизации\n",
    "sgd = SGD(learning_rate=0.03, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# Обучаем модель\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "\n",
    "# Оцениваем качество обучения модели на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Количество нейронов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.2741 - loss: 1.9645 - val_accuracy: 0.4980 - val_loss: 1.4293\n",
      "Точность работы на тестовых данных: 48.15%\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Задаем seed для повторяемости результатов\n",
    "numpy.random.seed(42)\n",
    "\n",
    "# Загружаем данные\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# Размер мини-выборки\n",
    "batch_size = 32\n",
    "# Количество классов изображений\n",
    "nb_classes = 10\n",
    "# Количество эпох для обучения\n",
    "nb_epoch = 1\n",
    "\n",
    "# Нормализуем данные\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Преобразуем метки в категории\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "# Формирование вектора, отвечающего за размерность входных данных: \n",
    "# либо (кол-во каналов, ширина, высота), либо (ширина, высота, кол-во каналов) \n",
    "# (в зависимости от значения параметра \"image_data_format\" в файле keras.json)\n",
    "shape_vector = X_train.shape[1:]\n",
    "# Первый сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=shape_vector, activation='relu'))\n",
    "# Второй сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# Первый слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Третий сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# Четвертый сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "# Слой преобразования данных из 2D представления в плоское\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой для классификации\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.5))\n",
    "# Выходной полносвязный слой\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# Задаем параметры оптимизации\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# Обучаем модель\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "\n",
    "# Оцениваем качество обучения модели на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n = 718"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 31ms/step - accuracy: 0.2355 - loss: 2.0532 - val_accuracy: 0.4706 - val_loss: 1.5022\n",
      "Точность работы на тестовых данных: 48.81%\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Задаем seed для повторяемости результатов\n",
    "numpy.random.seed(42)\n",
    "\n",
    "# Загружаем данные\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# Размер мини-выборки\n",
    "batch_size = 32\n",
    "# Количество классов изображений\n",
    "nb_classes = 10\n",
    "# Количество эпох для обучения\n",
    "nb_epoch = 1\n",
    "\n",
    "# Нормализуем данные\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Преобразуем метки в категории\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "# Формирование вектора, отвечающего за размерность входных данных: \n",
    "# либо (кол-во каналов, ширина, высота), либо (ширина, высота, кол-во каналов) \n",
    "# (в зависимости от значения параметра \"image_data_format\" в файле keras.json)\n",
    "shape_vector = X_train.shape[1:]\n",
    "# Первый сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=shape_vector, activation='relu'))\n",
    "# Второй сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# Первый слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Третий сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# Четвертый сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "# Слой преобразования данных из 2D представления в плоское\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой для классификации\n",
    "model.add(Dense(718, activation='relu'))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.5))\n",
    "# Выходной полносвязный слой\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# Задаем параметры оптимизации\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# Обучаем модель\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "\n",
    "# Оцениваем качество обучения модели на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоговая попытка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 27ms/step - accuracy: 0.2758 - loss: 1.9532 - val_accuracy: 0.5252 - val_loss: 1.3190\n",
      "Epoch 2/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.5203 - loss: 1.3294 - val_accuracy: 0.6074 - val_loss: 1.1088\n",
      "Epoch 3/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.6021 - loss: 1.1144 - val_accuracy: 0.6124 - val_loss: 1.1321\n",
      "Epoch 4/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.6483 - loss: 0.9879 - val_accuracy: 0.6772 - val_loss: 0.9350\n",
      "Epoch 5/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 31ms/step - accuracy: 0.6823 - loss: 0.8967 - val_accuracy: 0.7344 - val_loss: 0.7590\n",
      "Epoch 6/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.7150 - loss: 0.8065 - val_accuracy: 0.7330 - val_loss: 0.7714\n",
      "Epoch 7/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.7296 - loss: 0.7656 - val_accuracy: 0.7488 - val_loss: 0.7231\n",
      "Epoch 8/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 31ms/step - accuracy: 0.7460 - loss: 0.7320 - val_accuracy: 0.7288 - val_loss: 0.7903\n",
      "Epoch 9/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 31ms/step - accuracy: 0.7561 - loss: 0.7020 - val_accuracy: 0.7670 - val_loss: 0.6963\n",
      "Epoch 10/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.7627 - loss: 0.6650 - val_accuracy: 0.7604 - val_loss: 0.7189\n",
      "Epoch 11/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 31ms/step - accuracy: 0.7727 - loss: 0.6491 - val_accuracy: 0.7612 - val_loss: 0.6988\n",
      "Epoch 12/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.7863 - loss: 0.6079 - val_accuracy: 0.7686 - val_loss: 0.6743\n",
      "Epoch 13/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.7897 - loss: 0.5926 - val_accuracy: 0.7628 - val_loss: 0.7212\n",
      "Epoch 14/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.7986 - loss: 0.5741 - val_accuracy: 0.7720 - val_loss: 0.7037\n",
      "Epoch 15/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.8064 - loss: 0.5583 - val_accuracy: 0.7750 - val_loss: 0.6819\n",
      "Epoch 16/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.8044 - loss: 0.5569 - val_accuracy: 0.7468 - val_loss: 0.7373\n",
      "Epoch 17/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 32ms/step - accuracy: 0.8068 - loss: 0.5485 - val_accuracy: 0.7842 - val_loss: 0.6812\n",
      "Epoch 18/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.8162 - loss: 0.5285 - val_accuracy: 0.7642 - val_loss: 0.7085\n",
      "Epoch 19/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 31ms/step - accuracy: 0.8186 - loss: 0.5189 - val_accuracy: 0.7634 - val_loss: 0.7250\n",
      "Epoch 20/20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.8162 - loss: 0.5256 - val_accuracy: 0.7740 - val_loss: 0.6849\n",
      "Точность работы на тестовых данных: 75.68%\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Задаем seed для повторяемости результатов\n",
    "numpy.random.seed(42)\n",
    "\n",
    "# Загружаем данные\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# Размер мини-выборки\n",
    "batch_size = 32\n",
    "# Количество классов изображений\n",
    "nb_classes = 10\n",
    "# Количество эпох для обучения\n",
    "nb_epoch = 20\n",
    "\n",
    "# Нормализуем данные\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Преобразуем метки в категории\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "# Формирование вектора, отвечающего за размерность входных данных: \n",
    "# либо (кол-во каналов, ширина, высота), либо (ширина, высота, кол-во каналов) \n",
    "# (в зависимости от значения параметра \"image_data_format\" в файле keras.json)\n",
    "shape_vector = X_train.shape[1:]\n",
    "# Первый сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=shape_vector, activation='relu'))\n",
    "# Второй сверточный слой\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# Первый слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Третий сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# Четвертый сверточный слой\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.25))\n",
    "# Слой преобразования данных из 2D представления в плоское\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой для классификации\n",
    "model.add(Dense(718, activation='relu'))\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.5))\n",
    "# Выходной полносвязный слой\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# Задаем параметры оптимизации\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# Обучаем модель\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "\n",
    "# Оцениваем качество обучения модели на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_string = model.to_json()\n",
    "model.save_weights('mnist_model.weights.h5')\n",
    "\n",
    "\n",
    "with open(\"capitals.json\", \"w\") as my_file:\n",
    "    my_file.write(json_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">718</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,252,366</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">718</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,190</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_52 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_53 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_26 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_39 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_54 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_55 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_27 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_40 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_13 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m718\u001b[0m)            │     \u001b[38;5;34m2,252,366\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_41 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m718\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m7,190\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,325,124</span> (8.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,325,124\u001b[0m (8.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,325,124</span> (8.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,325,124\u001b[0m (8.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "json_filename = \"capitals.json\"\n",
    "with open(json_filename, \"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "\n",
    "# Создаем модель на основе загруженных данных\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Загружаем веса в модель\n",
    "h5_filename = \"mnist_model.weights.h5\"\n",
    "model.load_weights(h5_filename)\n",
    "\n",
    "# Перед использованием загруженной нейронной сети необходимо её скомпилировать\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Вывести начальные характеристики нейросети\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Обучите сверточную нейронную сеть распознаванию цифр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,950</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">187,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">800,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_56 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m75\u001b[0m)     │         \u001b[38;5;34m1,950\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_28 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m75\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_42 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m75\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_57 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │       \u001b[38;5;34m187,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_29 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_43 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_14 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │       \u001b[38;5;34m800,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_44 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">995,060</span> (3.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m995,060\u001b[0m (3.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">995,060</span> (3.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m995,060\u001b[0m (3.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - accuracy: 0.8078 - loss: 0.5796 - val_accuracy: 0.9812 - val_loss: 0.0611\n",
      "Точность работы на тестовых данных: 98.35%\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.backend import image_data_format\n",
    "\n",
    "# Устанавливаем seed для повторяемости результатов\n",
    "numpy.random.seed(42)\n",
    "\n",
    "# Загружаем данные\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Формирование вектора размерности (зависит от параметра из файла keras.json)\n",
    "input_shape = ((1, *X_train.shape[1:]) if \n",
    "               image_data_format() == 'channels_first' else \n",
    "               (*X_train.shape[1:], 1))\n",
    "\n",
    "# Преобразование размерности изображений\n",
    "X_train = X_train.reshape(X_train.shape[0], *input_shape)\n",
    "X_test = X_test.reshape(X_test.shape[0], *input_shape)\n",
    "\n",
    "# Нормализация данных\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Преобразуем метки в категории\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(75, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(100, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Компилируем модель\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Обучаем сеть\n",
    "model.fit(X_train, Y_train, batch_size=200, epochs=1, validation_split=0.2, \n",
    "          verbose=1)\n",
    "\n",
    "# Оцениваем качество обучения сети на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_string = model.to_json()\n",
    "model.save_weights('mnist_model.weights.h5')\n",
    "\n",
    "\n",
    "with open(\"capitals.json\", \"w\") as my_file:\n",
    "    my_file.write(json_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "json_filename = \"capitals.json\"\n",
    "with open(json_filename, \"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "\n",
    "# Создаем модель на основе загруженных данных\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Загружаем веса в модель\n",
    "h5_filename = \"mnist_model.weights.h5\"\n",
    "model.load_weights(h5_filename)\n",
    "\n",
    "# Перед использованием загруженной нейронной сети необходимо её скомпилировать\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread(\"./3.png\")\n",
    "img = img[:, :, 1]\n",
    "img = numpy.array(img.reshape(28, 28, 1))\n",
    "img = [img]\n",
    "img = numpy.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.argmax(model.predict(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
